# redis过期删除策略

两种方法搭配使用

**定期删除**：redis默认是每隔 100ms 就**随机抽取**一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！

**惰性删除：**惰性删除不会去主动删除数据，而是在访问数据的时候，再检查当前键值是否过期，如果过期则执行删除并返回 null 给客户端，如果没有过期则返回正常信息给客户端。它的优点是简单，不需要对过期的数据做额外的处理，只有在每次访问的时候才会检查键值是否过期，缺点是删除过期键不及时，造成了一定的空间浪费。

**定时删除：**创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作 

优点：节约内存，到时就删除，快速释放掉不必要的内存占用 

缺点：CPU压力很大，无论CPU此时负载量多高，均占用CPU，会影响redis服务器响应时间和指令吞吐量

但是仅仅通过设置过期时间还是有问题的。我们想一下：如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期key堆积在内存里，导致redis内存块耗尽了。怎么解决这个问题呢？

# redis内存淘汰机制

## lru是如何实现的

一般：hashmap加双向链表

redis中如何实现？

https://wenku.baidu.com/view/ae133fa4a3116c175f0e7cd184254b35eefd1aa3.html

# redis数据结构（5个基础数据结构和3个高级数据结构）

string list hash set mset

# kafka副本了解吗

kafka副本是为了保持数据的可靠性。kafka在topic可以设置复制因子表示要复制的副本数量，副本与托管它的服务器id相同。如果主题的复制因子设置为3，则kafka将为每个分区创建3个相同的副本。每个分区的副本中都会有一个leader，其他副本是不会被读取和写入的，目的是为了保存数据，该分区的其他副本为leader的追随者。当有一个broker失败后，该broker上leader将不可用，kafka会自动移除leader，再从其他副本中选一个作为新的leader。

# 为什么不让一个partition被同组的多consumer消费



# redis和mysql一致性解决方案

# 调用函数的过程

https://zhuanlan.zhihu.com/p/79760764  参考这个和下面的描述。

第一步：函数调用

1、对实参表从后向前，一次计算出实参的值，并且将值压栈。

2、将函数调用语句下一条语句的地址保存到在栈中，以便函数调用完成后返回。（将函数放到栈空间中称为压栈）。

3、跳转到函数体处。

第二步：函数体执行

4、如果函数体中定义了变量，将变量压栈

5、将每一个形参以栈中对应的实参值取代，执行函数体的功能体。

6、将函数体中的变量、保存到栈中的实参值，依次从栈中取出，释放栈空间（出栈）。

第三步：返回

7、返回过程执行的是函数体中的return语句。其过程是从栈中取出刚开始调用函数时压入的地址，跳转到函数的下一条语句。当return语句不带有表达式时，按照保存的地址返回，当return语句带有表达式时，将计算出的return表达式的值保存起来，然后再返回。