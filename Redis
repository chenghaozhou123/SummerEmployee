
单线程的Redis为啥这么快？
1.完全基于内存
2.IO多路复用
3.非关系性的，不像关系性数据库一样查找复杂
关于第1点比较好理解。Redis 绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，查找和操作的时间复杂度都是O(1)。



Redis持久化
持久化的几种方案：
RDB：将某一个时刻Redis的内存数据，以二进制的方案写入磁盘，速度快（因为相比较于AOF，不会写入一条指令就进行一次磁盘操作），会数据丢失（来不及做数据持久化），rdb具有更小的体积。
AOF：记录所有的操作命令，并以日志的形式追加到文件中，速度慢（对 内存操作一次就会对硬盘操作一次），不会数据丢失。
混合持久化方案：结合了RDB和AOF的优点，在写入时先把当前数据以RDB的形式写入文件的开头，再将后续的操作命令以AOF的格式存入文件，这样既能保证Redis重启时的速度，又能减低数据丢失的风险
先把操作指令写入到aof文件中，当文件大小达到阈值后就触发aof的重写机制，这时不会对aof文件进行精简而是把原有aof文件删除然后将内存的文件全部以快照的形式保存到rdb文件，同时记录当前正在执行
的命令以保证数据不丢失。
 
RDB的持久化方式是通过快照完成得，它是redis默认的持久化方式，配置如下。
Redis允许用户自定义的快照条件，当符合快照条件时，redis会自动执行快照操作。快照的条件可以由用户在配置文件中配置。配置格式如下：
save<seconds> <changes>
第一个参数是时间窗口，第二个是键的个数。也就是说在第一个时间参数配置范围内被更改的建的个数大于后面的changes时，即符合快照条件。当触发条件时，redis会自动将内存中的数据生成一份副本并存储在磁盘上。
这个过程称之为“快照”，除了上述规则之外，还有以下几种方式生成快照。
1.根据配置规则进行自动快照
2.用户执行save或者gbsave命令
3.执行flushall命令
4.执行复制时

AOF：每次执行命令后将命令本身记录下来
redis默认不开启，AOF采用日志的形式来记录每个写操作，并追加到文件中。开启后，执行更改Redis数据的命令时，就会把命令写入到AOF文件中。
Redis 重启时会根据日志文件的内容把写指令从前到后执行一次以完成数据的恢复工作。
数据都是实时持久化到磁盘吗？
虽然每次执行更改Redis数据库内容的操作时，AOF都会将命令记录在AOF文件中，但是事实上，由于操作系统的缓存机制，数据并没有真正地写入硬盘，而是进入了系统的硬盘缓存。在默认情况下系统每30秒会执行一次同步操作。以便将硬盘缓存中的内容真正地写入硬盘。
在这30秒的过程中如果系统异常退出则会导致硬盘缓存中的数据丢失。一般来说能够启用AOF的前提是业务场景不能容忍这样的数据损失，这个时候就需要Redis在写入AOF文件后主动要求系统将缓存内容同步到硬盘中。在redis.conf中通过如下配置来设置同步机制。
文件越来越大，怎么办？
由于AOF持久化是Redis不断将写命令记录到 AOF 文件中，随着Redis不断的运行，AOF 的文件会越来越大，文件越大，占用服务器内存越大以及 AOF 恢复要求时间越长。
例如set gupao 666，执行1000次，结果都是gupao=666。
为了解决这个问题，Redis新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。
可以使用命令下面这个命令主动触发重写
redis> bgrewriteaof
AOF 文件重写并不是对原文件进行重新整理，而是直接读取服务器现有的键值对，然后用一条命令去代替之前记录这个键值对的多条命令，生成一个新的文件后去替换原来的 AOF 文件。
启动过程与速度：
在启动时，Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相对于RDB会慢一些。

问题：重写过程中，AOF文件被更改了怎么办？
Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。
重写的流程是这样：
主进程会fork一个子进程出来进行AOF重写，这个重写过程并不是基于原有的aof文件来做的，而是有点类似于快照的方式，全量遍历内存中的数据，然后逐个序列到aof文件中。
在fork子进程这个过程中，服务端仍然可以对外提供服务，那这个时候重写的aof文件的数据和redis内存数据不一致了怎么办？不用担心，这个过程中，主进程的数据更新操作，会缓存到aof_rewrite_buf中，也就是单独开辟一块缓存来存储重写期间收到的命令，当子进程重写完以后再把缓存中的数据追加到新的aof文件。
当所有的数据全部追加到新的aof文件中后，把新的aof文件重命名正式的文件名字，此后所有的操作都会被写入新的aof文件。
如果在rewrite过程中出现故障，不会影响原来aof文件的正常工作，只有当rewrite完成后才会切换文件。因此这个rewrite过程是比较可靠的。
有图这里 https://baijiahao.baidu.com/s?id=1714299206113127177&wfr=spider&for=pc&searchword=redis%20fork

Redis的持久化原理：
https://blog.csdn.net/weixin_48380416/article/details/124308809
RDB是一次全量备份，即周期化的把Redis当前内存中的全量数据写入到一个快照文件中。Redis采用
多进程写时复制机制来实现快照的持久化，在持久化的过程中会fork()一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端的读写请求。子进程刚刚产生时，和父进程共享内存里面的代码段和数据段，
也就是说，父子进程的虚拟空间不同，但其对应的物理内存是同一个。（这是linux的机制，为了节约内存资源，所以尽可能的让父子进程共享内存，这样在进程分离的一瞬间，内存的增长几乎没有变化）
如果fork操作本身耗时过长，将导致父进程阻塞，可以通过命令查勘fork操作的耗时，若操作1s则需要优化。
写时复制：
如果主线程收到的客户端的读写请求，需要修改某块数据，那么这块数据就会被复制一份到内存，生成该数据的副本，主进程在该副本上进行修改操作。所以即使对某个数据进行了修改，Redis持久化到RDB中的数据也是未修改的数据，这也是把RDB文件称为"快照"文件的原因，子进程所看到的数据在它被创建的一瞬间就固定下来了，父进程修改的某个数据只是该数据的复制品。这里再深入一点，Redis内存中的全量数据由一个个的"数据段页面"组成，每个数据段页面的大小为4K，客户端要修改的数据在哪个页面中，就会复制一份这个页面到内存中，这个复制的过程称为"页面分离"，在持久化过程中，随着分离出的页面越来越多，内存就会持续增长，但是不会超过原内存的2倍，因为在一次持久化的过程中，几乎不会出现所有的页面都会分离的情况，读写请求针对的只是原数据中的小部分，大部分Redis数据还是"冷数据"。

正因为修改的部分数据会被额外的复制一份，所以会占用额外的内存，当在进行RDB持久化操作的过程中，与此同时如果持续往redis中写入的数据量越多，就会导致占用的额外内存消耗越大。

那么在此期间写入的数据最终去哪了呢？ 

写入的数据还是存在了内存当中，并没有写入当前的持久化文件中，等到下次进行RDB持久化时才会把 ” 写入的数据 ” 落盘到RDB文件中。

频繁执行全量快照的影响：
如果频繁执行全量快照，会带来两方面的开销：

频繁将全量数据写入磁盘，会给磁盘带来很大压力，可能出现前面的没做完，后面的又开始了。导致恶性循环。
bgsave 子进程需要通过 fork 操作从主线程创建出来，虽然，子进程在创建后不在会阻塞主线程，但是，fork这个创建过程本身会阻塞主线程，而且主线程内存越大，阻塞时间越长。

RDB 所在分区磁盘满了怎么办？
config set dir /mnt/data
开启RDB压缩：Redis 支持对 RDB 进行压缩，参数为 rdbcompression，设置为 yes 表示开启（默认开启的）。压缩不但可以节省磁盘空间，在创建主从时，也能更快的将全量备份传给从实例，因此建议开启压缩功能。
RDB 文件损坏检测：redis-check-rdb /mnt/data/redis/dump.rdb
单机多实例的 RDB 备份:
有些情况，我们会在单台服务器上部署多个 Redis 实例，但是使用配置文件中增加 save 的方式又怕几个实例 RDB 时间冲突，从而影响落盘速度。这种情况，可以使用脚本结合定时任务触发 bgsave 进行 RDB 备份。这样，同机器不同实例的 RDB 备份时间可以自定义错开，防止 IO 跑满带来的问题。（注意一定要设置好持久化的目录，防止多个实例共用同一目录）

那么 Redis 究竟怎么备份更好呢？RDB 尽管恢复会快很多，但是可靠性比 AOF 低，但是如果只使用 AOF，又会存在恢复慢的问题，因此，Redis 4.0 提出了混合使用 AOF 日志和内存快照的方法。因此对于 Redis 的备份，建议如下：

数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；aof-use-rdb-preamble 配置设置为 yes ；（Redis5.0版本以后默认是开启的）
如果允许分钟级别的数据丢失，可以只使用 RDB；
如果只用 AOF ，优先使用 everysec 的配置选项，因为其介于可靠性和性能之间；
